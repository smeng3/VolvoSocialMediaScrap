{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter Grader\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![data-x](https://raw.githubusercontent.com/afo/data-x-plaksha/master/imgsource/dx_logo.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### NAME:\n",
    "\n",
    "#### STUDENT ID:\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP for Sentiment Analysis on IMDB Movie Reviews\n",
    "\n",
    "In this assignment we will be exploring tools for Natural Language Processing (NLP). Our task is sentiment analysis for movie reviews and in that context we will touch upon multiple areas:\n",
    "\n",
    "- Feature engineering\n",
    "- Bag of words modeling\n",
    "- Word2Vec modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import Beautiful Soup, NumPy and Pandas, etc\n",
    "import bs4 as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    " \n",
    "# download NLTK classifiers - these are cached locally on your machine\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# import ml classifiers\n",
    "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
    "from nltk.stem import PorterStemmer     # parsing/stemmer\n",
    "from nltk.tag import pos_tag            # parts-of-speech tagging\n",
    "from nltk.corpus import wordnet         # sentiment scores\n",
    "from nltk.stem import WordNetLemmatizer # stem and context\n",
    "from nltk.corpus import stopwords       # stopwords\n",
    "from nltk.util import ngrams            # ngram iterator\n",
    "\n",
    "# import word2vec\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "___\n",
    "\n",
    "### Data Description\n",
    ">Data source: https://www.kaggle.com/c/word2vec-nlp-tutorial/data (originally from [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/))<br>\n",
    ">\n",
    ">Data Description:<br><br>\n",
    ">We will be using Kaggle's **Bag of Words Meets Bags of Popcorn** dataset to explore [IMBD](https://www.imdb.com/) movie review data. This dataset in included with the zip file distribution of your homework. Labeled training dataset consists of 25,000 IMDB movie reviews. The sentiment of the reviews are binary, meaning an IMDB rating < 5 results in a sentiment score of 0, and a rating >=7 have a sentiment score of 1 (no reviews with score 5 or 6 are included in the analysis). No individual movie has more than 30 reviews. The training data set is constructed in a balanced way so that there are an equal number of positive and negative reviews for each movie. There is also an unlabeled test set with 25,000 IMDB movie reviews. We don't use this for testing, but we do use it to improve unsupervised learning.\n",
    ">\n",
    ">Data Sets:<br>\n",
    ">* ```labeledTrainData.tsv``` --> The labeled training set. The file is tab-delimited and has a header row followed by 25,000 rows containing an id (numerical), sentiment (categorical), and text for each review (textual).<br>\n",
    ">* ```testData.tsv``` --> The unlabeled test set. 25,000 rows containing an id (numerical), and text for each review (textual). \n",
    ">\n",
    "> Further Reading:<br>\n",
    "> \n",
    "> * [Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).](http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "## Preparing data for classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided the function `review_cleaner` to preprocess reviews. Here is an overview of what it does:\n",
    "\n",
    "> - Removes HTML tags (using beautifulsoup)\n",
    "> - Extract emoticons (emotion symbols, aka smileys :D )\n",
    "> - Removes non-letters (using regular expression)\n",
    "> - Converts all words to lowercase letters and tokenizes them (using .split() method on the review strings, so that every word in the review is an element in a list)\n",
    "> - Removes all the English stopwords from the list of movie review words\n",
    "> - Applies either stemming or lemmatization, as indicated by the arguments\n",
    "> - Join the words back into one string seperated by space, append the emoticons to the end\n",
    "\n",
    "Note that you do not need to make any changes to `review_cleaner`. We will explore some examples of the cleaning process below.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def review_cleaner(review, lemmatize=True, stem=False):\n",
    "    '''\n",
    "        Clean and preprocess a review.\n",
    "            1. Remove HTML tags\n",
    "            2. Extract emoticons\n",
    "            3. Use regex to remove all special characters (only keep letters)\n",
    "            4. Make strings to lower case and tokenize / word split reviews\n",
    "            5. Remove English stopwords\n",
    "            6. Lemmatize\n",
    "            7. Rejoin to one string\n",
    "        \n",
    "        @review (type:str) is an unprocessed review string\n",
    "        @return (type:str) is a 6-step preprocessed review string\n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "    if lemmatize == True and stem == True:\n",
    "        raise RuntimeError(\"May not pass both lemmatize and stem flags\")\n",
    "\n",
    "    #1. Remove HTML tags\n",
    "    review = bs.BeautifulSoup(review).text    \n",
    "\n",
    "    #2. Use regex to find emoticons\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', review)\n",
    "\n",
    "    #3. Remove punctuation\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \",review)\n",
    "\n",
    "    #4. Tokenize into words (all lower case)\n",
    "    review = review.lower().split()\n",
    "\n",
    "    #5. Remove stopwords, Lemmatize, Stem\n",
    "    clean_review=[]\n",
    "    for word in review:\n",
    "        if word not in eng_stopwords:\n",
    "            if lemmatize is True:\n",
    "                word=wnl.lemmatize(word)\n",
    "            elif stem is True:\n",
    "                if word == 'oed':\n",
    "                    continue\n",
    "                word=ps.stem(word)\n",
    "            clean_review.append(word)\n",
    "\n",
    "    #6. Join the review to one sentence\n",
    "    review_processed = ' '.join(clean_review+emoticons)\n",
    "    \n",
    "    return review_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "To make things interesting, everyone gets to analyze a different review. Set `seed_value` to your favorite number, your name, or whatever else you'd like.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0_set_seed\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "seed_value = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0_set_seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a cleaned version of the randomly selected review\n",
    "my_review_id = int(hashlib.md5(str(seed_value).encode(\"utf-8\")).hexdigest()[:8], 16) % len(train.index)\n",
    "my_review = train.iloc[my_review_id][\"review\"]\n",
    "print(my_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Find the stopwords\n",
    "\n",
    "By manual inspection, find the first 5 stopwords in your chosen review. It might seem easier to write the code to do this, but the point of the exercise is to understand what the algorithm is doing.\n",
    "\n",
    "First review the list of stopwords below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the stopwords are\n",
    "print(\" \".join(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Inspect the review and look for the 5 first stopwords. Store them in `first_5_stopwords` in the order in which they appear in the review.\n",
    "\n",
    "e.g., \n",
    "```\n",
    "first_5_stopwords = ['having', 'the', 'to', 'some', 'of']\n",
    "```\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_stopwords_type\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "first_5_stopwords = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_stopwords_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_stopwords_length\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_stopwords_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_stopwords_match\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_stopwords_match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Lemmatization\n",
    "\n",
    "Lemmatization allows grouping of common forms of a word.\n",
    "\n",
    "Here are some examples of lemmatization:\n",
    "* images -> image\n",
    "* waxworks -> waxwork\n",
    "* sweets -> sweet\n",
    "\n",
    "By manual inspection, find the first 3 words in `my_review` that are lemmatized. Store them in `first_3_lemmatized` in the order in which they appear in the review.\n",
    "\n",
    "E.g.:\n",
    "```\n",
    "first_3_lemmatized = ['images', 'waxworks', 'sweets']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_lemmatization_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "first_3_lemmatized = ...\n",
    "\n",
    "print(\"Lemmatization examples:\")\n",
    "for w in first_3_lemmatized:\n",
    "    print(\"{} -> {}\".format(w, wnl.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_lemmatization_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_lemmatization_length\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_lemmatization_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_lemmatization_match\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_lemmatization_match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3 - Stemming\n",
    "\n",
    "Lemmatization allows grouping of common forms of a word.\n",
    "\n",
    "Here are some examples of stemming:\n",
    "* nonsense -> nonsens\n",
    "* investigates -> investig\n",
    "* disappearance -> disappear\n",
    "\n",
    "By manual inspection, find the first 3 words in `my_review` that are modified by stemming. Store them in `first_3_stemmed` in the order in which they appear in the review.\n",
    "\n",
    "E.g.:\n",
    "```\n",
    "first_3_stemmed = ['nonsense', 'investigates', 'disappearance']\n",
    "```\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_stemming_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "first_3_stemmed = ...\n",
    "\n",
    "print(\"Stemming examples:\")\n",
    "for w in first_3_stemmed:\n",
    "    print(\"{} -> {}\".format(w, ps.stem(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_stemming_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_stemming_length\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_stemming_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_stemming_match\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_stemming_match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "## Part II: Train and validate a sentiment analysis model using a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we have written the code to train the classifier for you. Your task will be to explore its performance characteristics with your own movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We vectorize the text using a bag of words model\n",
    "def get_vectorizer(ngram, max_features):\n",
    "    return CountVectorizer(ngram_range=(1, ngram),\n",
    "                             analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = review_cleaner,\n",
    "                             stop_words = None, \n",
    "                             max_features = max_features)\n",
    "\n",
    "# Model training\n",
    "def train_predict_sentiment(reviews, vectorizer, y=train[\"sentiment\"], ngram=1, max_features=1000, model_random_state=123):\n",
    "    '''\n",
    "        This function will:\n",
    "            1. split data into train and test set.\n",
    "            2. get n-gram counts from cleaned reviews \n",
    "            3. train a random forest model using train n-gram counts and y (labels)\n",
    "            4. test the model on your test split\n",
    "            5. print accuracy of sentiment prediction on test and training data\n",
    "            6. print confusion matrix on test data results\n",
    "\n",
    "            To change n-gram type, set value of ngram argument\n",
    "            To change the number of features you want the countvectorizer to generate, set the value of max_features argument\n",
    "            \n",
    "            @cleaned_review (type:str) is preprocessed string from review_cleaner()\n",
    "            @return none\n",
    "    '''\n",
    "\n",
    "    print(\"Creating the bag of words model!\\n\")\n",
    "    \n",
    "    # train / test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reviews, y, random_state=0, test_size=.2)\n",
    "\n",
    "    # Then we use fit_transform() to fit the model / learn the vocabulary,\n",
    "    # then transform the data into feature vectors.\n",
    "    # The input should be a list of strings. .toarray() converts to a numpy array\n",
    "    \n",
    "    train_bag = vectorizer.fit_transform(X_train)\n",
    "    if not isinstance(train_bag, np.ndarray):\n",
    "        train_bag = train_bag.toarray()\n",
    "    test_bag = vectorizer.transform(X_test)\n",
    "    if not isinstance(test_bag, np.ndarray):\n",
    "        test_bag = test_bag.toarray()\n",
    "\n",
    "    print(\"Training the random forest classifier!\\n\")\n",
    "    # Initialize a Random Forest classifier with 50 trees\n",
    "    forest = RandomForestClassifier(n_estimators = 50, random_state = model_random_state) \n",
    "\n",
    "    # Fit the forest to the training set, using the bag of words as \n",
    "    # features and the sentiment labels as the target variable\n",
    "    forest = forest.fit(train_bag, y_train)\n",
    "\n",
    "    # predict\n",
    "    train_predictions = forest.predict(train_bag)\n",
    "    test_predictions = forest.predict(test_bag)\n",
    "    \n",
    "    # validation\n",
    "    train_acc = metrics.accuracy_score(y_train, train_predictions)\n",
    "    valid_acc = metrics.accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    print(\" The training accuracy is: \", train_acc, \"\\n\", \"The validation accuracy is: \", valid_acc)\n",
    "    print()\n",
    "    print('CONFUSION MATRIX:')\n",
    "    print('         Predicted')\n",
    "    print('          neg pos')\n",
    "    print(' Actual')\n",
    "    c=confusion_matrix(y_test, test_predictions)\n",
    "    print('     neg  ',c[0])\n",
    "    print('     pos  ',c[1])\n",
    "\n",
    "    return forest\n",
    "\n",
    "# Print out the top features\n",
    "def top_features(forest, vectorizer, n):\n",
    "    #Extract feature importance\n",
    "    print('\\nTOP TEN IMPORTANT FEATURES:')\n",
    "    feature_text = vectorizer.get_feature_names().copy()\n",
    "    feature_importance = forest.feature_importances_.copy()\n",
    "    \n",
    "    indices = np.argsort(feature_importance)[::-1]\n",
    "    \n",
    "    top_n_ind = indices[:n]\n",
    "    top_n = list([vectorizer.get_feature_names()[ind] for ind in top_n_ind])\n",
    "    \n",
    "    print(top_n)\n",
    "\n",
    "# Print out whether the prediction is accurate\n",
    "def check_prediction(model, vectorizer, review, expected):\n",
    "    prediction = model.predict(vectorizer.transform([review]))[0]\n",
    "    sentiment = \"üëç\" if prediction else \"üëé\"\n",
    "    correct = \"\\x1b[92mcorrect\\x1b[0m\" if prediction == expected else \"\\x1b[31mincorrect\\x1b[0m\"\n",
    "    print(\"{} ‚ü∂ {} {}\".format(review, sentiment, correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Train Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train RFC model\n",
    "vectorizer = get_vectorizer(ngram=1, max_features=100)\n",
    "forest_model = train_predict_sentiment(reviews=train[\"review\"], vectorizer=vectorizer, y=train[\"sentiment\"])\n",
    "top_features(forest_model, vectorizer, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4 - Construct a positive sentiment review\n",
    "\n",
    "Think of a movie that you like and write a review for it. Store as a string in `good_review`. If the model doesn't give a positive prediction for your review iterate on it until it does.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_positive_review_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "good_review = ...\n",
    "check_prediction(forest_model, vectorizer, good_review, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_positive_review_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_positive_review_prediction\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_positive_review_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5 - Construct a negative sentiment review\n",
    "\n",
    "Think of a movie that you like and write a review for it. Store as a string in `bad_review`. If the model doesn't give a negative prediction for your review iterate on it until it does.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_negative_review_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "bad_review = ...\n",
    "check_prediction(forest_model, vectorizer, bad_review, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_negative_review_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_negative_review_prediction\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_negative_review_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6 - Construct a misclassified negative sentiment review\n",
    "\n",
    "Now try to write a review that you view as negative but the model views as positive. Iterate and experiment as necessary and store it as a string  `bad_review_error`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6_misclassified_review_type\n",
    "manual: false\n",
    "points: 0\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "bad_review_error = ...\n",
    "check_prediction(forest_model, vectorizer, bad_review_error, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6_misclassified_review_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6_misclasified_review_prediction\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6_misclasified_review_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sentences=[utils.simple_preprocess(review) for review in train['review']], size=100, seed=123, workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 - Explain Word2Vec similarity on display below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=['actress'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Pick one word similar to 'actress' and explain why it appears\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7_word2vec_similar_actress\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 - Explain Word2Vec comparison on display below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=['actress'], negative=['actor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Pick one word similar to 'actress' and dissimilar to 'actor' explain why it appears\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8_word2vec_similar_actress_dissimilar_actor\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_feature_vecs(reviews, model):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one \n",
    "\n",
    "    \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    reviewFeatureVecs = []\n",
    "    # Loop through the reviews\n",
    "    for counter, review in enumerate(reviews):\n",
    "        \n",
    "        # Print a status message every 5000th review\n",
    "        if (counter + 1) % 5000. == 0.:\n",
    "            print(\"Review %d of %d\" % (counter + 1, len(reviews)))\n",
    "\n",
    "        # Function to average all of the word vectors in a given paragraph\n",
    "        featureVec = []\n",
    "\n",
    "        # Loop over each word in the review and, if it is in the model's\n",
    "        # vocaublary, add its feature vector to the total\n",
    "        for n,word in enumerate(utils.simple_preprocess(review)):\n",
    "            if word in index2word_set: \n",
    "                featureVec.append(model.wv[word])\n",
    "\n",
    "        # Average the word vectors for a \n",
    "        featureVec = np.mean(featureVec, axis=0).reshape(1,-1)\n",
    "\n",
    "        reviewFeatureVecs.append(featureVec)\n",
    "\n",
    "    return np.concatenate(reviewFeatureVecs, axis=0)\n",
    "\n",
    "w2v_vectorizer = FunctionTransformer(lambda x: get_avg_feature_vecs(x, w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v2v_forest_model = train_predict_sentiment(reviews=train[\"review\"], vectorizer=w2v_vectorizer, y=train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 9 - compare Word2Vec to Bag of Words\n",
    "\n",
    "Comment on how Word2Vec compares with the Bag of Words Model. Please use the template below for your answer\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q9_word2vec_comparison\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Complete answers below*:\n",
    "\n",
    "* **Is it an improvement?**\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "* **How significant is the difference?**\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "* **Is this a fair and meaningful comparision? Why or why not?**\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "* **What other experiments might you run to further compare?**\n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Add more training data\n",
    "\n",
    "You will now try to further improve the performance of the Word2Vec model by enhancing it with unlabeled data. \n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10_word2vec_train_more\n",
    "manual: true\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unlabeled test data set\n",
    "more_training_data = pd.read_csv(\"testData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 rows\n",
    "more_training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model so that it learns from the reviews in more_training_data.\n",
    "# This involves two steps: 1/ updating the vocabulary, 2/ training the model.\n",
    "# Be sure to preprocess the reviews. Your code should modify and update w2v_model\n",
    "\n",
    "# Your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_forest_model = train_predict_sentiment(reviews=train[\"review\"], vectorizer=FunctionTransformer(lambda x: get_avg_feature_vecs(x, w2v_model)), y=train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 - Comment on the impact of more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Complete answers below*:\n",
    "\n",
    "* **Did adding more training data improve the model?**\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "* **How significant is the difference?**\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "* **Why could one expect a model to improve even when provided with unlabeled data?**\n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Prediction Analysis\n",
    "\n",
    "Check to see how the Word2Vec model works on the reviews that you wrote previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_prediction(w2v_forest_model, w2v_vectorizer, good_review, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_prediction(v2v_forest_model, w2v_vectorizer, bad_review, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"With Bag of Words:\")\n",
    "check_prediction(forest_model, vectorizer, bad_review_error, 0)\n",
    "\n",
    "print(\"With Word2Vec:\")\n",
    "check_prediction(v2v_forest_model, w2v_vectorizer, bad_review_error, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 11 - how does the Word2Vec model compare to Bag of Words?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q11_word2vec_comment\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "Just comment, don't change your reviews to achieve a particular outcome.\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Complete answers below:*\n",
    "\n",
    "* **Is your positive review classified correctly by Word2Vec?**\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "* **Is your negative review classified correctly by Word2Vec?**\n",
    "\n",
    "*your answer here*\n",
    "\n",
    "* **Is your negative review misclassified by Bag of Words now classified correctly by Word2Vec?**\n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 12 - create a review where the models disagree\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q12_word2vec_split_decision_exists\n",
    "manual: false\n",
    "points: 0\n",
    "-->\n",
    "\n",
    "If your originally misclassified negative review was properly classified by Word2Vec you may use it to answer this question.\n",
    "If not, construct some other review that is properly classified by one model and improperly classified by the other model. Store that review as a string in `split_prediction`. Store the expected prediction in `split_prediction_expected` as 1 for positive sentiment or 0 for negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "split_prediction = ...\n",
    "split_prediction_expected = ...\n",
    "\n",
    "print(\"With Bag of Words:\")\n",
    "check_prediction(forest_model, vectorizer, split_prediction, split_prediction_expected)\n",
    "\n",
    "print(\"With Word2Vec:\")\n",
    "check_prediction(v2v_forest_model, w2v_vectorizer, split_prediction, split_prediction_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q12_word2vec_split_decision_defined\n",
    "manual: true\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q12_word2vec_split_decision_defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q12_word2vec_split_decision_predict\n",
    "manual: false\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q12_word2vec_split_decision_predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submit\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output.\n",
    "**Please save before submitting!**\n",
    "\n",
    "<!-- EXPECT 6 EXPORTED QUESTIONS -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
